{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing INTERNET speeds in Morocco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import geopandas as gp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm  # progress bar in Jupyter\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Download data\n",
    "\n",
    "First, download OOKLA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarter_start(year: int, q: int) -> datetime:\n",
    "    if not 1 <= q <= 4:\n",
    "        raise ValueError(\"Quarter must be within [1, 2, 3, 4]\")\n",
    "    month = [1, 4, 7, 10]\n",
    "    return datetime(year, month[q - 1], 1)\n",
    "\n",
    "def quarter_start(year: int, q: int) -> datetime:\n",
    "    if not 1 <= q <= 4:\n",
    "        raise ValueError(\"Quarter must be within [1, 2, 3, 4]\")\n",
    "    month = [1, 4, 7, 10]\n",
    "    return datetime(year, month[q - 1], 1)\n",
    "\n",
    "def quarter_end(year: int, q: int) -> datetime:\n",
    "    if q == 4:\n",
    "        return datetime(year + 1, 1, 1)\n",
    "    return quarter_start(year, q + 1)\n",
    "\n",
    "def get_tile_url(service_type: str, year: int, q: int) -> str | None:\n",
    "    dt = quarter_start(year, q)\n",
    "    end_dt = quarter_end(year, q)\n",
    "    now = datetime.utcnow()\n",
    "\n",
    "    if now < end_dt:\n",
    "        print(f\"‚è© Skipping {service_type} {year} Q{q} (quarter not yet complete)\")\n",
    "        return None\n",
    "\n",
    "    base_url = \"https://ookla-open-data.s3-us-west-2.amazonaws.com/shapefiles/performance\"\n",
    "    url = f\"{base_url}/type%3D{service_type}/year%3D{dt:%Y}/quarter%3D{q}/{dt:%Y-%m-%d}_performance_{service_type}_tiles.zip\"\n",
    "    return url\n",
    "\n",
    "def download_file_with_progress(url: str, output_dir: str = \"data\") -> str:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    local_filename = os.path.join(output_dir, url.split(\"/\")[-1])\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 Kibibyte\n",
    "\n",
    "    t = tqdm(total=total_size, unit='iB', unit_scale=True, desc=f\"Downloading {os.path.basename(local_filename)}\")\n",
    "\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        for data in response.iter_content(block_size):\n",
    "            t.update(len(data))\n",
    "            f.write(data)\n",
    "\n",
    "    t.close()\n",
    "\n",
    "    if total_size != 0 and t.n != total_size:\n",
    "        print(\"‚ö†Ô∏è WARNING: Download might be incomplete.\")\n",
    "    \n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configure ctype,years,and quarters as you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è© Skipping fixed 2025 Q2 (quarter not yet complete)\n",
      "‚è© Skipping fixed 2025 Q3 (quarter not yet complete)\n",
      "‚è© Skipping fixed 2025 Q4 (quarter not yet complete)\n",
      "‚è© Skipping mobile 2025 Q2 (quarter not yet complete)\n",
      "‚è© Skipping mobile 2025 Q3 (quarter not yet complete)\n",
      "‚è© Skipping mobile 2025 Q4 (quarter not yet complete)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145205/3529908371.py:21: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n"
     ]
    }
   ],
   "source": [
    "ctype = [\"fixed\",\"mobile\"]\n",
    "years = [2023,2025]\n",
    "quarters = [1, 2, 3, 4]\n",
    "for t in ctype :\n",
    "    for year in years :\n",
    "        for q in quarters :\n",
    "            url = get_tile_url(t, year, q)\n",
    "           # download_file_with_progress(url) #uncomment to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Morocco = gp.read_file(\"data/Morocco/morocco.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77c05028e0043fe900ec26e69876fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üì• Loading tiles:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 2025-01-01_performance_fixed_tiles.zip: 6364159 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2025-01-01_performance_fixed_tiles_morocco.shp (18874 features)\n",
      "‚úÖ 2024-07-01_performance_mobile_tiles.zip: 3773658 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-07-01_performance_mobile_tiles_morocco.shp (12335 features)\n",
      "‚úÖ 2024-01-01_performance_mobile_tiles.zip: 3674000 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-01-01_performance_mobile_tiles_morocco.shp (12563 features)\n",
      "‚úÖ 2025-01-01_performance_mobile_tiles.zip: 3388115 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2025-01-01_performance_mobile_tiles_morocco.shp (12002 features)\n",
      "‚úÖ 2024-10-01_performance_fixed_tiles.zip: 6561086 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-10-01_performance_fixed_tiles_morocco.shp (18414 features)\n",
      "‚úÖ 2024-04-01_performance_fixed_tiles.zip: 6492072 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-04-01_performance_fixed_tiles_morocco.shp (18484 features)\n",
      "‚úÖ 2024-01-01_performance_fixed_tiles.zip: 6655986 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-01-01_performance_fixed_tiles_morocco.shp (19127 features)\n",
      "‚úÖ 2024-07-01_performance_fixed_tiles.zip: 6655377 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-07-01_performance_fixed_tiles_morocco.shp (18587 features)\n",
      "‚úÖ 2024-04-01_performance_mobile_tiles.zip: 3703161 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-04-01_performance_mobile_tiles_morocco.shp (13523 features)\n",
      "‚úÖ 2024-10-01_performance_mobile_tiles.zip: 3551267 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-10-01_performance_mobile_tiles_morocco.shp (12340 features)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List all matching zip files\n",
    "zip_files = [f for f in os.listdir(\"data\") if f.endswith(\".zip\") and \"tiles\" in f]\n",
    "\n",
    "# Progress bar for loading\n",
    "for filename in tqdm(zip_files, desc=\"Loading tiles\"):\n",
    "    path = os.path.join(\"data\", filename)\n",
    "    try:\n",
    "        gdf = gp.read_file(path)\n",
    "        print(f\"LOADED : {filename}: {len(gdf)} features\")\n",
    "        name = filename\n",
    "        gdf = gdf.to_crs(Morocco.crs)\n",
    "        morocco_tiles = gp.clip(gdf, Morocco)\n",
    "        output_name = name.replace(\".zip\", \"_morocco.shp\")\n",
    "        output_path = os.path.join(\"MoroccoData\", output_name)\n",
    "        morocco_tiles.to_file(output_path, driver=\"ESRI Shapefile\")\n",
    "        print(f\"SAVED: {output_path} ({len(morocco_tiles)} features)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {filename}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extracted from link[ https://github.com/teamookla/ookla-open-data/edit/master/README.md ]\n",
    "\n",
    "#### Tile Attributes\n",
    "Each tile contains the following adjoining attributes:\n",
    "\n",
    "| Field Name        | Type        | Description                                                                                                                             | Notes                                                                                                                                                                              |\n",
    "|-------------------|-------------|-----------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `avg_d_kbps`      | Integer     | The average download speed of all tests performed in the tile, represented in kilobits per second.                                      |                                                                                                                                                                                    |\n",
    "| `avg_u_kbps`      | Integer     | The average upload speed of all tests performed in the tile, represented in kilobits per second.                                        |                                                                                                                                                                                    |\n",
    "| `avg_lat_ms`      | Integer     | The average latency of all tests performed in the tile, represented in milliseconds                                                     |                                                                                                                                                                                    |\n",
    "| `avg_lat_down_ms` | Integer     | The average latency under load of all tests performed in the tile as measured during the download phase of the test. Represented in ms. | Parquet-only. Added 2023-02-23 beginning in Q4 2022 dataset. This column is sparsely populated-- some rows will have a null value as not all versions of Speedtest can perform this measurement. |\n",
    "| `avg_lat_up_ms`   | Integer     | The average latency under load of all tests performed in the tile as measured during the upload phase of the test. Represented in ms.   | Parquet-only. Added 2023-02-23 beginning in Q4 2022 dataset. This column is sparsely populated-- some rows will have a null value as not all versions of Speedtest can perform this measurement. |\n",
    "| `tests`           | Integer     | The number of tests taken in the tile. |\n",
    "| `devices`         | Integer     | The number of unique devices contributing tests in the tile. |\n",
    "| `quadkey`         | Text        | The quadkey representing the tile.  |\n",
    "| `tile_x`\t\t\t| Numeric\t  | X coordinate of the tile's centroid.| Added 2023-07-01 beginning in the Q3 2023 dataset.\n",
    "| `tile_y`          | Numeric     | Y coordinate of the tile's centroid.| Added 2023-07-01 beginning in the Q3 2023 dataset.\n",
    "\n",
    "\n",
    "#### Quadkeys\n",
    "\n",
    "[Quadkeys](https://docs.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system) can act as a unique identifier for the tile. This can be useful for joining data spatially from multiple periods (quarters), creating coarser spatial aggregations without using geospatial functions, spatial indexing, partitioning, and an alternative for storing and deriving the tile geometry.\n",
    "\n",
    "#### Layers\n",
    "Two layers are distributed as separate sets of files:\n",
    "\n",
    "* `performance_mobile_tiles` - Tiles containing tests taken from mobile devices with GPS-quality location and a cellular connection type (e.g. 4G LTE, 5G NR).\n",
    "* `performance_fixed_tiles` - Tiles containing tests taken from mobile devices with GPS-quality location and a non-cellular connection type (e.g. WiFi, ethernet).\n",
    "\n",
    "#### Time Period and Update Frequency\n",
    "\n",
    "Layers are generated based on a quarter year of data (three months) and files will be updated and added on a quarterly basis. A `/year=2020/quarter=1/` period, the first quarter of the year 2020, would include all data generated on or after `2020-01-01` and before `2020-04-01`.\n",
    "\n",
    "Data is subject to be reaggregated regularly in order to honor Data Subject Access Requests (DSAR) as is applicable in certain jurisdictions under laws including but not limited to General Data Protection Regulation (GDPR), California Consumer Privacy Act (CCPA), and Lei Geral de Prote√ß√£o de Dados (LGPD). Therefore, data accessed at different times may result in variation in the total number of tests, tiles, and resulting performance metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD MOROCCO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab40ef2ba94d4bf68d811e46f7f9fab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Morocco tiles:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED : 2024-04-01_performance_fixed_tiles_morocco.shp: 18484 features\n",
      "LOADED : 2024-07-01_performance_fixed_tiles_morocco.shp: 18587 features\n",
      "LOADED : 2024-10-01_performance_fixed_tiles_morocco.shp: 18414 features\n",
      "LOADED : 2024-04-01_performance_mobile_tiles_morocco.shp: 13523 features\n",
      "LOADED : 2024-01-01_performance_fixed_tiles_morocco.shp: 19127 features\n",
      "LOADED : 2024-07-01_performance_mobile_tiles_morocco.shp: 12335 features\n",
      "LOADED : 2025-01-01_performance_fixed_tiles_morocco.shp: 18874 features\n",
      "LOADED : 2024-10-01_performance_mobile_tiles_morocco.shp: 12340 features\n",
      "LOADED : 2025-01-01_performance_mobile_tiles_morocco.shp: 12002 features\n",
      "LOADED : 2024-01-01_performance_mobile_tiles_morocco.shp: 12563 features\n",
      "‚úÖ Saved combined dataset to: all_quarters_combined.gpkg\n",
      "‚úÖ Saved differences dataset to: all_quarters_differences.gpkg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_FOLDER = \"MoroccoData\"\n",
    "\n",
    "# Grab only shapefiles that end with \"_morocco.shp\"\n",
    "Morocco_Data_files = [\n",
    "    f for f in os.listdir(DATA_FOLDER) \n",
    "    if f.endswith(\"_morocco.shp\")\n",
    "]\n",
    "\n",
    "# This will accumulate your ‚Äúwide‚Äù data\n",
    "final_gdf = None\n",
    "\n",
    "# Regex to capture:\n",
    "#   2024-01-01_performance_fixed_tiles_morocco.shp\n",
    "#   group(1) => 2024-01-01\n",
    "#   group(2) => fixed or mobile\n",
    "filename_pattern = re.compile(r'(\\d{4}-\\d{2}-\\d{2})_.*?(fixed|mobile).*?_morocco\\.shp')\n",
    "\n",
    "for filename in tqdm(Morocco_Data_files, desc=\"Loading Morocco tiles\"):\n",
    "    path = os.path.join(DATA_FOLDER, filename)\n",
    "    try:\n",
    "        gdf = gp.read_file(path)\n",
    "        print(f\"LOADED : {filename}: {len(gdf)} features\")\n",
    "\n",
    "        # Extract quarter/date and type from filename\n",
    "        match = filename_pattern.search(filename)\n",
    "        if not match:\n",
    "            print(f\"‚ùå Could not parse quarter/type from {filename}\")\n",
    "            continue\n",
    "        \n",
    "        quarter_str = match.group(1)  # e.g. \"2024-01-01\"\n",
    "        conn_type  = match.group(2)   # e.g. \"fixed\" or \"mobile\"\n",
    "        \n",
    "        # Build a rename map. We keep 'quadkey' and 'geometry' the same\n",
    "        rename_map = {}\n",
    "        for col in gdf.columns:\n",
    "            if col not in ['quadkey', 'geometry']:\n",
    "                # Prepend <quarter>_<type>_\n",
    "                new_col = f\"{quarter_str}_{conn_type}_{col}\"\n",
    "                rename_map[col] = new_col\n",
    "        \n",
    "        # Rename columns\n",
    "        gdf_renamed = gdf.rename(columns=rename_map)\n",
    "        \n",
    "        # If final_gdf is None, just store this one.\n",
    "        if final_gdf is None:\n",
    "            final_gdf = gdf_renamed\n",
    "        else:\n",
    "            # We'll do a full outer merge only on 'quadkey'\n",
    "            # Because tile_x & tile_y do not exist in your shapefiles\n",
    "            gdf_no_geom = gdf_renamed.drop(columns=['geometry'])\n",
    "            final_gdf = final_gdf.merge(\n",
    "                gdf_no_geom,\n",
    "                on='quadkey',\n",
    "                how='outer'\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {filename}: {e}\")\n",
    "\n",
    "# At this point, final_gdf is your ‚Äúwide‚Äù GeoDataFrame with columns like:\n",
    "#   quadkey, geometry, 2024-01-01_fixed_avg_d_kbps, 2024-01-01_fixed_avg_u_kbps, etc.\n",
    "\n",
    "# Save as a GeoPackage instead of ESRI Shapefile so you don‚Äôt lose column names:\n",
    "final_out = \"all_quarters_combined.gpkg\"\n",
    "final_gdf.to_file(final_out, driver=\"GPKG\")\n",
    "print(f\"‚úÖ Saved combined dataset to: {final_out}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Create a second file that has differences \n",
    "# between consecutive quarters for each type\n",
    "import pandas as pd\n",
    "\n",
    "diff_gdf = final_gdf.copy()\n",
    "\n",
    "# We‚Äôll parse all columns that match e.g. 2024-01-01_fixed_avg_d_kbps\n",
    "col_pattern = re.compile(r'(\\d{4}-\\d{2}-\\d{2})_(fixed|mobile)_(.*)')\n",
    "\n",
    "# Build a structure to group columns by (type, metric), e.g. (fixed, avg_d_kbps).\n",
    "quarter_type_to_metrics = {}\n",
    "\n",
    "for col in diff_gdf.columns:\n",
    "    m = col_pattern.match(col)\n",
    "    if m:\n",
    "        q_str = m.group(1)\n",
    "        t_str = m.group(2)\n",
    "        metric_name = m.group(3)\n",
    "        \n",
    "        # Keep track of columns by quarter\n",
    "        quarter_type_to_metrics.setdefault((t_str, metric_name), []).append(q_str)\n",
    "\n",
    "# For each (type, metric), sort quarters & build difference columns\n",
    "for (conn_type, metric_name), quarter_list in quarter_type_to_metrics.items():\n",
    "    quarter_list_sorted = sorted(quarter_list)\n",
    "    for i in range(1, len(quarter_list_sorted)):\n",
    "        prev_q = quarter_list_sorted[i-1]\n",
    "        curr_q = quarter_list_sorted[i]\n",
    "        \n",
    "        prev_col = f\"{prev_q}_{conn_type}_{metric_name}\"\n",
    "        curr_col = f\"{curr_q}_{conn_type}_{metric_name}\"\n",
    "        \n",
    "        # If for some reason we‚Äôre missing a column, skip\n",
    "        if prev_col not in diff_gdf.columns or curr_col not in diff_gdf.columns or metric_name in ['tests', 'devices']:\n",
    "            continue\n",
    "        \n",
    "        diff_col_name = f\"D_{curr_q}_M_{prev_q}_{conn_type}_{metric_name}\"\n",
    "        diff_gdf[diff_col_name] = diff_gdf[curr_col] - diff_gdf[prev_col]\n",
    "\n",
    "# Save differences as well, again in a GeoPackage\n",
    "diff_out = \"all_quarters_differences.gpkg\"\n",
    "diff_gdf.to_file(diff_out, driver=\"GPKG\")\n",
    "print(f\"‚úÖ Saved differences dataset to: {diff_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
