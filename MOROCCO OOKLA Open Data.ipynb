{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing INTERNET speeds in Morocco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import geopandas as gp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm  # progress bar in Jupyter\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Download data\n",
    "\n",
    "First, download OOKLA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarter_start(year: int, q: int) -> datetime:\n",
    "    if not 1 <= q <= 4:\n",
    "        raise ValueError(\"Quarter must be within [1, 2, 3, 4]\")\n",
    "    month = [1, 4, 7, 10]\n",
    "    return datetime(year, month[q - 1], 1)\n",
    "\n",
    "def quarter_start(year: int, q: int) -> datetime:\n",
    "    if not 1 <= q <= 4:\n",
    "        raise ValueError(\"Quarter must be within [1, 2, 3, 4]\")\n",
    "    month = [1, 4, 7, 10]\n",
    "    return datetime(year, month[q - 1], 1)\n",
    "\n",
    "def quarter_end(year: int, q: int) -> datetime:\n",
    "    if q == 4:\n",
    "        return datetime(year + 1, 1, 1)\n",
    "    return quarter_start(year, q + 1)\n",
    "\n",
    "def get_tile_url(service_type: str, year: int, q: int) -> str | None:\n",
    "    dt = quarter_start(year, q)\n",
    "    end_dt = quarter_end(year, q)\n",
    "    now = datetime.utcnow()\n",
    "\n",
    "    if now < end_dt:\n",
    "        print(f\"‚è© Skipping {service_type} {year} Q{q} (quarter not yet complete)\")\n",
    "        return None\n",
    "\n",
    "    base_url = \"https://ookla-open-data.s3-us-west-2.amazonaws.com/shapefiles/performance\"\n",
    "    url = f\"{base_url}/type%3D{service_type}/year%3D{dt:%Y}/quarter%3D{q}/{dt:%Y-%m-%d}_performance_{service_type}_tiles.zip\"\n",
    "    return url\n",
    "\n",
    "def download_file_with_progress(url: str, output_dir: str = \"data\") -> str:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    local_filename = os.path.join(output_dir, url.split(\"/\")[-1])\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 Kibibyte\n",
    "\n",
    "    t = tqdm(total=total_size, unit='iB', unit_scale=True, desc=f\"Downloading {os.path.basename(local_filename)}\")\n",
    "\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        for data in response.iter_content(block_size):\n",
    "            t.update(len(data))\n",
    "            f.write(data)\n",
    "\n",
    "    t.close()\n",
    "\n",
    "    if total_size != 0 and t.n != total_size:\n",
    "        print(\"‚ö†Ô∏è WARNING: Download might be incomplete.\")\n",
    "    \n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configure ctype,years,and quarters as you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è© Skipping fixed 2025 Q2 (quarter not yet complete)\n",
      "‚è© Skipping fixed 2025 Q3 (quarter not yet complete)\n",
      "‚è© Skipping fixed 2025 Q4 (quarter not yet complete)\n",
      "‚è© Skipping mobile 2025 Q2 (quarter not yet complete)\n",
      "‚è© Skipping mobile 2025 Q3 (quarter not yet complete)\n",
      "‚è© Skipping mobile 2025 Q4 (quarter not yet complete)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145205/3529908371.py:21: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n"
     ]
    }
   ],
   "source": [
    "ctype = [\"fixed\",\"mobile\"]\n",
    "years = [2023,2025]\n",
    "quarters = [1, 2, 3, 4]\n",
    "for t in ctype :\n",
    "    for year in years :\n",
    "        for q in quarters :\n",
    "            url = get_tile_url(t, year, q)\n",
    "           # download_file_with_progress(url) #uncomment to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Morocco = gp.read_file(\"data/Morocco/morocco.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77c05028e0043fe900ec26e69876fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üì• Loading tiles:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 2025-01-01_performance_fixed_tiles.zip: 6364159 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2025-01-01_performance_fixed_tiles_morocco.shp (18874 features)\n",
      "‚úÖ 2024-07-01_performance_mobile_tiles.zip: 3773658 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-07-01_performance_mobile_tiles_morocco.shp (12335 features)\n",
      "‚úÖ 2024-01-01_performance_mobile_tiles.zip: 3674000 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-01-01_performance_mobile_tiles_morocco.shp (12563 features)\n",
      "‚úÖ 2025-01-01_performance_mobile_tiles.zip: 3388115 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2025-01-01_performance_mobile_tiles_morocco.shp (12002 features)\n",
      "‚úÖ 2024-10-01_performance_fixed_tiles.zip: 6561086 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-10-01_performance_fixed_tiles_morocco.shp (18414 features)\n",
      "‚úÖ 2024-04-01_performance_fixed_tiles.zip: 6492072 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-04-01_performance_fixed_tiles_morocco.shp (18484 features)\n",
      "‚úÖ 2024-01-01_performance_fixed_tiles.zip: 6655986 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-01-01_performance_fixed_tiles_morocco.shp (19127 features)\n",
      "‚úÖ 2024-07-01_performance_fixed_tiles.zip: 6655377 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-07-01_performance_fixed_tiles_morocco.shp (18587 features)\n",
      "‚úÖ 2024-04-01_performance_mobile_tiles.zip: 3703161 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-04-01_performance_mobile_tiles_morocco.shp (13523 features)\n",
      "‚úÖ 2024-10-01_performance_mobile_tiles.zip: 3551267 features | CRS: EPSG:4326 | Columns: ['quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices', 'geometry']\n",
      "‚úÖ Saved: MoroccoData/2024-10-01_performance_mobile_tiles_morocco.shp (12340 features)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List all matching zip files\n",
    "zip_files = [f for f in os.listdir(\"data\") if f.endswith(\".zip\") and \"tiles\" in f]\n",
    "\n",
    "# Progress bar for loading\n",
    "for filename in tqdm(zip_files, desc=\"Loading tiles\"):\n",
    "    path = os.path.join(\"data\", filename)\n",
    "    try:\n",
    "        gdf = gp.read_file(path)\n",
    "        print(f\"LOADED : {filename}: {len(gdf)} features\")\n",
    "        name = filename\n",
    "        gdf = gdf.to_crs(Morocco.crs)\n",
    "        morocco_tiles = gp.clip(gdf, Morocco)\n",
    "        output_name = name.replace(\".zip\", \"_morocco.shp\")\n",
    "        output_path = os.path.join(\"MoroccoData\", output_name)\n",
    "        morocco_tiles.to_file(output_path, driver=\"ESRI Shapefile\")\n",
    "        print(f\"SAVED: {output_path} ({len(morocco_tiles)} features)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {filename}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extracted from link[ https://github.com/teamookla/ookla-open-data/edit/master/README.md ]\n",
    "\n",
    "#### Tile Attributes\n",
    "Each tile contains the following adjoining attributes:\n",
    "\n",
    "| Field Name        | Type        | Description                                                                                                                             | Notes                                                                                                                                                                              |\n",
    "|-------------------|-------------|-----------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `avg_d_kbps`      | Integer     | The average download speed of all tests performed in the tile, represented in kilobits per second.                                      |                                                                                                                                                                                    |\n",
    "| `avg_u_kbps`      | Integer     | The average upload speed of all tests performed in the tile, represented in kilobits per second.                                        |                                                                                                                                                                                    |\n",
    "| `avg_lat_ms`      | Integer     | The average latency of all tests performed in the tile, represented in milliseconds                                                     |                                                                                                                                                                                    |\n",
    "| `avg_lat_down_ms` | Integer     | The average latency under load of all tests performed in the tile as measured during the download phase of the test. Represented in ms. | Parquet-only. Added 2023-02-23 beginning in Q4 2022 dataset. This column is sparsely populated-- some rows will have a null value as not all versions of Speedtest can perform this measurement. |\n",
    "| `avg_lat_up_ms`   | Integer     | The average latency under load of all tests performed in the tile as measured during the upload phase of the test. Represented in ms.   | Parquet-only. Added 2023-02-23 beginning in Q4 2022 dataset. This column is sparsely populated-- some rows will have a null value as not all versions of Speedtest can perform this measurement. |\n",
    "| `tests`           | Integer     | The number of tests taken in the tile. |\n",
    "| `devices`         | Integer     | The number of unique devices contributing tests in the tile. |\n",
    "| `quadkey`         | Text        | The quadkey representing the tile.  |\n",
    "| `tile_x`\t\t\t| Numeric\t  | X coordinate of the tile's centroid.| Added 2023-07-01 beginning in the Q3 2023 dataset.\n",
    "| `tile_y`          | Numeric     | Y coordinate of the tile's centroid.| Added 2023-07-01 beginning in the Q3 2023 dataset.\n",
    "\n",
    "\n",
    "#### Quadkeys\n",
    "\n",
    "[Quadkeys](https://docs.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system) can act as a unique identifier for the tile. This can be useful for joining data spatially from multiple periods (quarters), creating coarser spatial aggregations without using geospatial functions, spatial indexing, partitioning, and an alternative for storing and deriving the tile geometry.\n",
    "\n",
    "#### Layers\n",
    "Two layers are distributed as separate sets of files:\n",
    "\n",
    "* `performance_mobile_tiles` - Tiles containing tests taken from mobile devices with GPS-quality location and a cellular connection type (e.g. 4G LTE, 5G NR).\n",
    "* `performance_fixed_tiles` - Tiles containing tests taken from mobile devices with GPS-quality location and a non-cellular connection type (e.g. WiFi, ethernet).\n",
    "\n",
    "#### Time Period and Update Frequency\n",
    "\n",
    "Layers are generated based on a quarter year of data (three months) and files will be updated and added on a quarterly basis. A `/year=2020/quarter=1/` period, the first quarter of the year 2020, would include all data generated on or after `2020-01-01` and before `2020-04-01`.\n",
    "\n",
    "Data is subject to be reaggregated regularly in order to honor Data Subject Access Requests (DSAR) as is applicable in certain jurisdictions under laws including but not limited to General Data Protection Regulation (GDPR), California Consumer Privacy Act (CCPA), and Lei Geral de Prote√ß√£o de Dados (LGPD). Therefore, data accessed at different times may result in variation in the total number of tests, tiles, and resulting performance metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD MOROCCO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab40ef2ba94d4bf68d811e46f7f9fab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Morocco tiles:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED : 2024-04-01_performance_fixed_tiles_morocco.shp: 18484 features\n",
      "LOADED : 2024-07-01_performance_fixed_tiles_morocco.shp: 18587 features\n",
      "LOADED : 2024-10-01_performance_fixed_tiles_morocco.shp: 18414 features\n",
      "LOADED : 2024-04-01_performance_mobile_tiles_morocco.shp: 13523 features\n",
      "LOADED : 2024-01-01_performance_fixed_tiles_morocco.shp: 19127 features\n",
      "LOADED : 2024-07-01_performance_mobile_tiles_morocco.shp: 12335 features\n",
      "LOADED : 2025-01-01_performance_fixed_tiles_morocco.shp: 18874 features\n",
      "LOADED : 2024-10-01_performance_mobile_tiles_morocco.shp: 12340 features\n",
      "LOADED : 2025-01-01_performance_mobile_tiles_morocco.shp: 12002 features\n",
      "LOADED : 2024-01-01_performance_mobile_tiles_morocco.shp: 12563 features\n",
      "‚úÖ Saved combined dataset to: all_quarters_combined.gpkg\n",
      "‚úÖ Saved differences dataset to: all_quarters_differences.gpkg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_FOLDER = \"MoroccoData\"\n",
    "\n",
    "# Grab only shapefiles that end with \"_morocco.shp\"\n",
    "Morocco_Data_files = [\n",
    "    f for f in os.listdir(DATA_FOLDER) \n",
    "    if f.endswith(\"_morocco.shp\")\n",
    "]\n",
    "\n",
    "# This will accumulate your ‚Äúwide‚Äù data\n",
    "final_gdf = None\n",
    "\n",
    "# Regex to capture:\n",
    "#   2024-01-01_performance_fixed_tiles_morocco.shp\n",
    "#   group(1) => 2024-01-01\n",
    "#   group(2) => fixed or mobile\n",
    "filename_pattern = re.compile(r'(\\d{4}-\\d{2}-\\d{2})_.*?(fixed|mobile).*?_morocco\\.shp')\n",
    "\n",
    "for filename in tqdm(Morocco_Data_files, desc=\"Loading Morocco tiles\"):\n",
    "    path = os.path.join(DATA_FOLDER, filename)\n",
    "    try:\n",
    "        gdf = gp.read_file(path)\n",
    "        print(f\"LOADED : {filename}: {len(gdf)} features\")\n",
    "\n",
    "        # Extract quarter/date and type from filename\n",
    "        match = filename_pattern.search(filename)\n",
    "        if not match:\n",
    "            print(f\"‚ùå Could not parse quarter/type from {filename}\")\n",
    "            continue\n",
    "        \n",
    "        quarter_str = match.group(1)  # e.g. \"2024-01-01\"\n",
    "        conn_type  = match.group(2)   # e.g. \"fixed\" or \"mobile\"\n",
    "        \n",
    "        # Build a rename map. We keep 'quadkey' and 'geometry' the same\n",
    "        rename_map = {}\n",
    "        for col in gdf.columns:\n",
    "            if col not in ['quadkey', 'geometry']:\n",
    "                # Prepend <quarter>_<type>_\n",
    "                new_col = f\"{quarter_str}_{conn_type}_{col}\"\n",
    "                rename_map[col] = new_col\n",
    "        \n",
    "        # Rename columns\n",
    "        gdf_renamed = gdf.rename(columns=rename_map)\n",
    "        \n",
    "        # If final_gdf is None, just store this one.\n",
    "        if final_gdf is None:\n",
    "            final_gdf = gdf_renamed\n",
    "        else:\n",
    "            # We'll do a full outer merge only on 'quadkey'\n",
    "            # Because tile_x & tile_y do not exist in your shapefiles\n",
    "            gdf_no_geom = gdf_renamed.drop(columns=['geometry'])\n",
    "            final_gdf = final_gdf.merge(\n",
    "                gdf_no_geom,\n",
    "                on='quadkey',\n",
    "                how='outer'\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {filename}: {e}\")\n",
    "\n",
    "# At this point, final_gdf is your ‚Äúwide‚Äù GeoDataFrame with columns like:\n",
    "#   quadkey, geometry, 2024-01-01_fixed_avg_d_kbps, 2024-01-01_fixed_avg_u_kbps, etc.\n",
    "\n",
    "# Save as a GeoPackage instead of ESRI Shapefile so you don‚Äôt lose column names:\n",
    "final_out = \"all_quarters_combined.gpkg\"\n",
    "final_gdf.to_file(final_out, driver=\"GPKG\")\n",
    "print(f\"‚úÖ Saved combined dataset to: {final_out}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Create a second file that has differences \n",
    "# between consecutive quarters for each type\n",
    "import pandas as pd\n",
    "\n",
    "diff_gdf = final_gdf.copy()\n",
    "\n",
    "# We‚Äôll parse all columns that match e.g. 2024-01-01_fixed_avg_d_kbps\n",
    "col_pattern = re.compile(r'(\\d{4}-\\d{2}-\\d{2})_(fixed|mobile)_(.*)')\n",
    "\n",
    "# Build a structure to group columns by (type, metric), e.g. (fixed, avg_d_kbps).\n",
    "quarter_type_to_metrics = {}\n",
    "\n",
    "for col in diff_gdf.columns:\n",
    "    m = col_pattern.match(col)\n",
    "    if m:\n",
    "        q_str = m.group(1)\n",
    "        t_str = m.group(2)\n",
    "        metric_name = m.group(3)\n",
    "        \n",
    "        # Keep track of columns by quarter\n",
    "        quarter_type_to_metrics.setdefault((t_str, metric_name), []).append(q_str)\n",
    "\n",
    "# For each (type, metric), sort quarters & build difference columns\n",
    "for (conn_type, metric_name), quarter_list in quarter_type_to_metrics.items():\n",
    "    quarter_list_sorted = sorted(quarter_list)\n",
    "    for i in range(1, len(quarter_list_sorted)):\n",
    "        prev_q = quarter_list_sorted[i-1]\n",
    "        curr_q = quarter_list_sorted[i]\n",
    "        \n",
    "        prev_col = f\"{prev_q}_{conn_type}_{metric_name}\"\n",
    "        curr_col = f\"{curr_q}_{conn_type}_{metric_name}\"\n",
    "        \n",
    "        # If for some reason we‚Äôre missing a column, skip\n",
    "        if prev_col not in diff_gdf.columns or curr_col not in diff_gdf.columns or metric_name in ['tests', 'devices']:\n",
    "            continue\n",
    "        \n",
    "        diff_col_name = f\"D_{curr_q}_M_{prev_q}_{conn_type}_{metric_name}\"\n",
    "        diff_gdf[diff_col_name] = diff_gdf[curr_col] - diff_gdf[prev_col]\n",
    "\n",
    "# Save differences as well, again in a GeoPackage\n",
    "diff_out = \"all_quarters_differences.gpkg\"\n",
    "diff_gdf.to_file(diff_out, driver=\"GPKG\")\n",
    "print(f\"‚úÖ Saved differences dataset to: {diff_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "population_commune.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m shp_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopulation_commune.shp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 2. Chargement\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m communes \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshp_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 3. Exploration rapide\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(communes\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\geopandas\\io\\file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\geopandas\\io\\file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    544\u001b[0m     )\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyogrio\\geopandas.py:265\u001b[0m, in \u001b[0;36mread_dataframe\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[0;32m    285\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyogrio\\raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:1240\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:220\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDataSourceError\u001b[0m: population_commune.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# 1. Chemin vers votre shapefile\n",
    "shp_path = \"C:\\Users\\Ahmed\\OoklaOpenDataMorocco\\populaion_commune.shp\"  \n",
    "\n",
    "# 2. Chargement\n",
    "communes = gpd.read_file(shp_path)\n",
    "\n",
    "# 3. Exploration rapide\n",
    "print(communes.head())\n",
    "print(\"CRS :\", communes.crs)\n",
    "print(\"Colonnes disponibles :\", communes.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
